# Citation Intent Classifier

Bu proje, TÃ¼rkÃ§e akademik metinlerdeki atÄ±f cÃ¼mlelerini analiz ederek atÄ±f niyetini (citation intent) belirlemeye 
yÃ¶neliktir. 

KullanÄ±lan modeller aÅŸaÄŸÄ±daki gibi listelenmektedir.
* dbmdz/bert-base-turkish-cased
* dbmdz/electra-base-turkish-cased-discriminator
* xlm-roberta-base
* microsoft/deberta-v3-base


## ğŸ“ AmaÃ§

TÃ¼rkÃ§e atÄ±f cÃ¼mlelerinin ÅŸu 6 sÄ±nÄ±ftan birine ait olup olmadÄ±ÄŸÄ±nÄ± sÄ±nÄ±flandÄ±rmak:

* background
* discuss
* basis
* support
* differ
* other

## ğŸ”§ Kurulum

Python 3.9+ ve PyTorch ile uyumlu bir conda ortamÄ±nda:

```bash
  conda create --name <ortam_adi> python=3.9
  conda activate <ortam_adi>
  pip install -r requirements.txt
```

## ğŸ“‚ KlasÃ¶r YapÄ±sÄ±

```
base_directory/
â”œâ”€â”€ train_v1.py                    # Standart sÄ±nÄ±flandÄ±rma iÃ§in eÄŸitim (model deÄŸiÅŸken olarak verilebilir)
â”œâ”€â”€ train_v2.py                    # HiyerarÅŸik sÄ±nÄ±flandÄ±rma iÃ§in eÄŸitim (model deÄŸiÅŸken olarak verilebilir)
â”œâ”€â”€ checkpoints/                   # Kaydedilen model ve optimizer durumlarÄ±
â”œâ”€â”€ predict_v1.py                  # Standart sÄ±nÄ±flandÄ±rma iÃ§in tahmin (model deÄŸiÅŸken olarak verilebilir)
â”œâ”€â”€ predict_v1.py                  # HiyerarÅŸik sÄ±nÄ±flandÄ±rma iÃ§in tahmin (model deÄŸiÅŸken olarak verilebilir)
â”œâ”€â”€ generic_model.py               # Generic TransformerClassifier sÄ±nÄ±fÄ±dÄ±r. Parametre olarak model ismi alÄ±r ve sonunda sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± vardÄ±r
â”œâ”€â”€ dataset.py                     # SQL veya CSV tabanlÄ± veri Ã§ekme
â”œâ”€â”€ model.py                       # [DEPRECIATE] BERTurkClassifier modeli
â”œâ”€â”€ train.py                       # [DEPRECIATE] EÄŸitme dÃ¶ngÃ¼sÃ¼, checkpoint desteÄŸi ile
â”œâ”€â”€ extract_embeddings.py          # CLS, mean, max, attention-weighted embedding Ã§Ä±kÄ±ÅŸÄ±
â”œâ”€â”€ analyze_clusters.py            # Elbow, silhouette ve t-SNE analizleri
â”œâ”€â”€ cls_to_closest_tokens.py       # CLS embedding ile en yakÄ±n tokenlarÄ± bulma
â”œâ”€â”€ embedding_to_closest_tokens.py # TÃ¼m embedding'ler iÃ§in yakÄ±n token analizi
â”œâ”€â”€ predict_untrained.py           # EÄŸitim Ã¶ncesi embedding'leri gÃ¶zlemleme
â”œâ”€â”€ output/                        # .npy dosyalarÄ± ve analiz grafikleri
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.csv                  # SQL'den Ã§ekilen veya dÄ±ÅŸa aktarÄ±lan veri
â”‚   â””â”€â”€ data_v1.csv                # SQL'den Ã§ekilen veya dÄ±ÅŸa aktarÄ±lan temizlenmiÅŸ veri
```

## ğŸ“ƒ Veri KaynaÄŸÄ±

Veriler MySQL veritabanÄ±ndan ÅŸu sorgularla alÄ±nÄ±r:

* Etiketli: `cec_citation_intent` Ã¼zerinden
* Etiketsiz: `cec_citation` tablosundan

> CSV varsa tekrar SQL sorgusu Ã§alÄ±ÅŸmaz; `CitationDataset` otomatik kontrol eder.

## ğŸ“… EÄŸitim AÅŸamalarÄ±

***train_v1.py:*** Bir metnin atÄ±f niyetini tÃ¼m sÄ±nÄ±flar arasÄ±nda doÄŸrudan tek bir adÄ±mda sÄ±nÄ±flandÄ±ran standart bir 
Transformer modelini eÄŸitir.

***train_v2.py:*** AtÄ±f niyetini iki aÅŸamalÄ± hiyerarÅŸik bir yaklaÅŸÄ±mla sÄ±nÄ±flandÄ±ran iki ayrÄ± model eÄŸitir; ilk model 
metnin "background" olup olmadÄ±ÄŸÄ±nÄ± anlarken, ikinci model "non-background" metinleri kendi alt tÃ¼rlerine ayÄ±rÄ±r.

```bash
  python train_v1.py
  python train_v2.py
```

Model `checkpoints/berturk_classifier_checkpoint.pt` dosyasÄ±na kaydedilir ve tekrar Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda kaldÄ±ÄŸÄ± yerden devam eder.

## ğŸ“ˆ Embedding TÃ¼rleri

```bash
python extract_embeddings.py
```

AÅŸaÄŸÄ±daki tÃ¼rler Ã§Ä±karÄ±lÄ±r ve `output/` klasÃ¶rÃ¼ne zaman etiketli olarak kaydedilir:

* CLS (pooler\_output)
* Mean pooling
* Max pooling
* Attention-weighted pooling

Her bir `.npy` dosyasÄ± `202505201434_cls_embedding.npy` gibi timestamp'li ÅŸekilde adlandÄ±rÄ±lÄ±r.

## ğŸ” Analiz

```bash
python analyze_clusters.py
```

* Her embedding tÃ¼rÃ¼ iÃ§in t-SNE, silhouette score ve elbow grafiÄŸi oluÅŸturur
* `output/` klasÃ¶rÃ¼ne `tsne`, `silhouette`, `elbow` gÃ¶rselleri kaydedilir

## ğŸ” Alternatif Analizler

```bash
python TEST_cls_to_closest_tokens.py
python embedding_to_closest_tokens.py
```

Verilen cÃ¼mle embedding'lerinin sÃ¶zlÃ¼kteki en yakÄ±n token'larla benzerlik analizi yapÄ±lÄ±r.

## ğŸš© Notlar

* Model BERTurk: `dbmdz/bert-base-turkish-cased`
* AtÄ±f intent sÄ±nÄ±flandÄ±rmasÄ± 6 sÄ±nÄ±flÄ± softmax ile yapÄ±lÄ±r
* Checkpoint: model, optimizer, scheduler ve epoch bilgilerini iÃ§erir
* `CitationDataset`: CSV varsa onu kullanÄ±r, yoksa SQL sorgusu Ã§alÄ±ÅŸtÄ±rÄ±r ve CSV oluÅŸturur

---

Bu proje, TÃ¼rkÃ§e akademik metinlerde yapay zekÃ¢ tabanlÄ± anlam Ã§Ä±karÄ±mÄ± Ã§alÄ±ÅŸmasÄ±nÄ±n bir parÃ§asÄ±dÄ±r.
