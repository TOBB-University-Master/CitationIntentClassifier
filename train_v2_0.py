import torch
import torch.nn as nn
import os
import logging
import pickle
import json

from torch import Generator
from sklearn.metrics import classification_report, accuracy_score
from torch.utils.data import DataLoader, random_split, Subset
from transformers import get_scheduler, AutoTokenizer
from torch.optim import AdamW
from collections import Counter
from dataset import CitationDataset
from model_v1 import BerturkClassifier
from tqdm import tqdm


"""
     EÄŸitim sÃ¼recindeki Ã¶nemli bilgileri (epoch baÅŸlangÄ±cÄ±, kayÄ±p deÄŸeri, doÄŸruluk vb.) hem bir dosyaya (training.log) 
     hem de konsola yazdÄ±rmak iÃ§in bir loglama sistemi kurar
"""
def setup_logging(log_file):
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file, mode='a'),
            logging.StreamHandler()
        ]
    )


def evaluate(model, data_loader, device, label_names):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for batch in data_loader:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["label"].to(device)

            logits = model(input_ids, attention_mask)
            preds = torch.argmax(logits, dim=1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    acc = accuracy_score(all_labels, all_preds)
    report = classification_report(all_labels, all_preds, target_names=label_names, zero_division=0)
    return acc, report

def display_samples(loader_name, data_loader, tokenizer, num_samples=1000):
    """
    Verilen bir DataLoader'dan belirtilen sayÄ±da Ã¶rneÄŸi yazdÄ±rÄ±r.
    """
    print(f"\n--- {loader_name} Ä°Ã§in {num_samples} Ã–rnek Veri ---")

    # DataLoader'Ä± bir iteratÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r
    data_iter = iter(data_loader)

    # Ã–rnekleri al ve yazdÄ±r
    for i in range(num_samples):
        try:
            sample = next(data_iter)

            # batch_size > 1 olabileceÄŸinden her zaman batch'in ilk Ã¶rneÄŸini alÄ±yoruz
            input_ids = sample['input_ids'][0]
            label = sample['label'][0]

            # Token ID'lerini tekrar okunabilir metne dÃ¶nÃ¼ÅŸtÃ¼r
            decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)

            print(f"\nÃ–rnek #{i + 1}:")
            print(f"  Okunabilir Metin: '{decoded_text}'")
            print(f"  AtanmÄ±ÅŸ Label ID: {label.item()}")

        except StopIteration:
            print(f"\nUyarÄ±: '{loader_name}' iÃ§inde {num_samples} adetten az veri var.")
            break
    print("-" * (len(loader_name) + 25))

# TODO: Ãœst Seviye SÄ±nÄ±flandÄ±rÄ±cÄ± EÄŸitimi
def train_top_level_classifier(config):
    """
    Modeli 'Background' vs 'Non-Background' olarak ikili sÄ±nÄ±flandÄ±rma iÃ§in eÄŸitir.
    """
    log_file = os.path.join(config["checkpoint_path_binary"], "training_binary.log")
    setup_logging(log_file)
    logging.info("--- ADIM 1: Ãœst Seviye (Ä°kili) SÄ±nÄ±flandÄ±rÄ±cÄ± EÄŸitimi BaÅŸlatÄ±lÄ±yor ---")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    torch.manual_seed(config["seed"])

    # Tokenizer (ortak)
    tokenizer = AutoTokenizer.from_pretrained(config["model_name"])
    special_tokens_dict = {'additional_special_tokens': ['<CITE>']}
    tokenizer.add_special_tokens(special_tokens_dict)

    # Veri Seti (Ä°kili gÃ¶rev iÃ§in)
    logging.info("Ä°kili sÄ±nÄ±flandÄ±rma iÃ§in veri seti yÃ¼kleniyor...")
    full_dataset = CitationDataset(tokenizer=tokenizer, mode="labeled", csv_path="data/data_v1.csv", task='binary')
    num_labels = len(full_dataset.get_label_names())  # Bu 2 olmalÄ±
    label_names_list = full_dataset.get_label_names()
    logging.info(f"SÄ±nÄ±f sayÄ±sÄ±: {num_labels}, SÄ±nÄ±flar: {label_names_list}")

    # Label encoder'Ä± kaydet
    with open(config["label_encoder_binary_path"], "wb") as f:
        pickle.dump(full_dataset.label_encoder, f)
    logging.info(f"Ä°kili label encoder ÅŸuraya kaydedildi: {config['label_encoder_binary_path']}")

    # Veriyi ayÄ±rma (Train/Val/Test)
    generator = Generator().manual_seed(config["seed"])
    train_val_size = int(0.8 * len(full_dataset))
    test_size = len(full_dataset) - train_val_size
    train_val_dataset, test_dataset = random_split(
        full_dataset,
        [train_val_size, test_size],
        generator=generator
    )

    # 3. ADIM: %80'LÄ°K KISMI %85 (TRAIN) VE %15 (VALIDATION) OLARAK AYIRMA
    logging.info("EÄŸitim/DoÄŸrulama seti, %85 EÄŸitim ve %15 DoÄŸrulama olarak ayrÄ±lÄ±yor...")
    train_size = int(0.85 * len(train_val_dataset))
    val_size = len(train_val_dataset) - train_size
    train_dataset, val_dataset = random_split(
        train_val_dataset,
        [train_size, val_size],
        generator=generator
    )

    train_loader = DataLoader(train_dataset, batch_size=config["batch_size"], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config["batch_size"])
    test_loader = DataLoader(test_dataset, batch_size=config["batch_size"])

    if config["print_labels"]:
        label_names = full_dataset.label_encoder.classes_

        # Her bir veri setindeki (Subset) etiketleri sayan bir yardÄ±mcÄ± fonksiyon
        # Her bir veri setindeki (Subset) etiketleri sayan bir yardÄ±mcÄ± fonksiyon
        def log_class_distribution(subset, name):
            # DÃœZELTME: Subset iÃ§indeki her bir elemanÄ±n etiketini doÄŸrudan okuyoruz.
            # Bu yÃ¶ntem, iÃ§ iÃ§e geÃ§miÅŸ Subset'lerde bile sorunsuz Ã§alÄ±ÅŸÄ±r.
            labels = [subset[i]['label'].item() for i in range(len(subset))]

            counts = Counter(labels)
            label_names = subset.dataset.label_encoder.classes_ if not isinstance(subset.dataset,
                                                                                  Subset) else subset.dataset.dataset.label_encoder.classes_
            logging.info(f"--- {name} SÄ±nÄ±f DaÄŸilÄ±mÄ± ---")
            logging.info(f"Toplam Ã–rnek: {len(subset)}")
            for label_id, count in sorted(counts.items()):
                # `label_names`'i doÄŸru yerden aldÄ±ÄŸÄ±mÄ±zdan emin olalÄ±m
                original_dataset = subset
                while isinstance(original_dataset, Subset):
                    original_dataset = original_dataset.dataset

                label_names = original_dataset.label_encoder.classes_
                logging.info(f"    {label_names[label_id]} (ID: {label_id}): {count}")

        log_class_distribution(train_dataset, "EÄŸitim Seti")
        log_class_distribution(val_dataset, "DoÄŸrulama Seti")
        log_class_distribution(test_dataset, "Test Seti")
        exit(0)

    # Model, Optimizer, Scheduler
    model = BerturkClassifier(model_name=config["model_name"], num_labels=num_labels)
    model.bert.resize_token_embeddings(len(tokenizer))
    model.to(device)

    optimizer = AdamW(model.parameters(), lr=config["lr"])
    criterion = nn.CrossEntropyLoss()
    num_training_steps = len(train_loader) * config["epochs"]
    lr_scheduler = get_scheduler("linear", optimizer=optimizer, num_warmup_steps=0,
                                 num_training_steps=num_training_steps)

    start_epoch = 0
    best_val_acc = 0.0
    if os.path.exists(config["resume_checkpoint_path_binary"]):
        checkpoint = torch.load(config["resume_checkpoint_path_binary"], map_location=device)
        model.load_state_dict(checkpoint["model_state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        lr_scheduler.load_state_dict(checkpoint["scheduler_state_dict"])
        start_epoch = checkpoint["epoch"] + 1
        best_val_acc = checkpoint.get("best_val_acc", 0.0)  # Eski checkpoint'lerle uyumluluk iÃ§in .get()
        logging.info(f"Checkpoint bulundu, eÄŸitime {start_epoch}. epoch'tan devam ediliyor.")
    else:
        logging.info("Yeni bir eÄŸitim baÅŸlatÄ±lÄ±yor, checkpoint bulunamadÄ±.")


    for epoch in range(start_epoch,config["epochs"]):
        model.train()
        total_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{config['epochs']} (Binary)")
        for batch in progress_bar:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["label"].to(device)

            logits = model(input_ids, attention_mask)
            loss = criterion(logits, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            lr_scheduler.step()
            total_loss += loss.item()
            progress_bar.set_postfix(loss=f"{total_loss / (progress_bar.n + 1):.4f}")

        checkpoint_data = {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scheduler_state_dict": lr_scheduler.state_dict(),
            "best_val_acc": best_val_acc
        }
        torch.save(checkpoint_data, config["resume_checkpoint_path_binary"])

        # DeÄŸerlendirme
        val_acc, val_report = evaluate(model, val_loader, device, label_names_list)
        logging.info(f"\nEpoch {epoch + 1} - DoÄŸrulama BaÅŸarÄ±mÄ±: {val_acc:.4f}\n{val_report}")

        # En iyi modeli kaydetme
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            logging.info(f"ğŸš€ Yeni en iyi ikili model kaydediliyor: {best_val_acc:.4f}")
            torch.save(model.state_dict(), config["best_model_path_binary"])

    # EÄŸitim sonrasÄ± test
    logging.info("\n--- Ä°kili Model Test SÃ¼reci ---")
    model.load_state_dict(torch.load(config['best_model_path_binary']))
    test_acc, test_report = evaluate(model, test_loader, device, label_names_list)
    logging.info(f"\n--- Ä°KÄ°LÄ° TEST SONUÃ‡LARI ---\nTest BaÅŸarÄ±mÄ±: {test_acc:.4f}\n{test_report}")


# TODO: Uzman SÄ±nÄ±flandÄ±rÄ±cÄ± EÄŸitimi
def train_expert_classifier(config):
    """
    Modeli 'Non-Background' olan 4 sÄ±nÄ±f Ã¼zerinde eÄŸitir.
    """
    log_file = os.path.join(config["checkpoint_path_multiclass"], "training_multiclass.log")
    setup_logging(log_file)
    logging.info("\n--- ADIM 2: Uzman (Ã‡ok SÄ±nÄ±flÄ±) SÄ±nÄ±flandÄ±rÄ±cÄ± EÄŸitimi BaÅŸlatÄ±lÄ±yor ---")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    torch.manual_seed(config["seed"])

    # Tokenizer (ortak)
    tokenizer = AutoTokenizer.from_pretrained(config["model_name"])
    special_tokens_dict = {'additional_special_tokens': ['<CITE>']}
    tokenizer.add_special_tokens(special_tokens_dict)

    # Veri Seti (Ã‡ok sÄ±nÄ±flÄ± gÃ¶rev iÃ§in)
    logging.info("Ã‡ok sÄ±nÄ±flÄ± (Non-Background) veri seti yÃ¼kleniyor...")
    full_dataset = CitationDataset(tokenizer=tokenizer, mode="labeled", csv_path="data/data_v1.csv", task='multiclass')
    num_labels = len(full_dataset.get_label_names())  # Bu 4 olmalÄ±
    label_names_list = full_dataset.get_label_names()
    logging.info(f"SÄ±nÄ±f sayÄ±sÄ±: {num_labels}, SÄ±nÄ±flar: {label_names_list}")

    # Label encoder'Ä± kaydet
    with open(config["label_encoder_multiclass_path"], "wb") as f:
        pickle.dump(full_dataset.label_encoder, f)
    logging.info(f"Ã‡ok sÄ±nÄ±flÄ± label encoder ÅŸuraya kaydedildi: {config['label_encoder_multiclass_path']}")


    # Veriyi ayÄ±rma (Train/Val/Test)
    generator = Generator().manual_seed(config["seed"])
    train_val_size = int(0.8 * len(full_dataset))
    test_size = len(full_dataset) - train_val_size
    train_val_dataset, test_dataset = random_split(
        full_dataset,
        [train_val_size, test_size],
        generator=generator
    )

    # 3. ADIM: %80'LÄ°K KISMI %85 (TRAIN) VE %15 (VALIDATION) OLARAK AYIRMA
    logging.info("EÄŸitim/DoÄŸrulama seti, %85 EÄŸitim ve %15 DoÄŸrulama olarak ayrÄ±lÄ±yor...")
    train_size = int(0.85 * len(train_val_dataset))
    val_size = len(train_val_dataset) - train_size
    train_dataset, val_dataset = random_split(
        train_val_dataset,
        [train_size, val_size],
        generator=generator
    )

    train_loader = DataLoader(train_dataset, batch_size=config["batch_size"], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config["batch_size"])
    test_loader = DataLoader(test_dataset, batch_size=config["batch_size"])

    if config["print_labels"]:
        label_names = full_dataset.label_encoder.classes_

        # Her bir veri setindeki (Subset) etiketleri sayan bir yardÄ±mcÄ± fonksiyon
        # Her bir veri setindeki (Subset) etiketleri sayan bir yardÄ±mcÄ± fonksiyon
        def log_class_distribution(subset, name):
            # DÃœZELTME: Subset iÃ§indeki her bir elemanÄ±n etiketini doÄŸrudan okuyoruz.
            # Bu yÃ¶ntem, iÃ§ iÃ§e geÃ§miÅŸ Subset'lerde bile sorunsuz Ã§alÄ±ÅŸÄ±r.
            labels = [subset[i]['label'].item() for i in range(len(subset))]

            counts = Counter(labels)
            label_names = subset.dataset.label_encoder.classes_ if not isinstance(subset.dataset,
                                                                                  Subset) else subset.dataset.dataset.label_encoder.classes_
            logging.info(f"--- {name} SÄ±nÄ±f DaÄŸilÄ±mÄ± ---")
            logging.info(f"Toplam Ã–rnek: {len(subset)}")
            for label_id, count in sorted(counts.items()):
                # `label_names`'i doÄŸru yerden aldÄ±ÄŸÄ±mÄ±zdan emin olalÄ±m
                original_dataset = subset
                while isinstance(original_dataset, Subset):
                    original_dataset = original_dataset.dataset

                label_names = original_dataset.label_encoder.classes_
                logging.info(f"    {label_names[label_id]} (ID: {label_id}): {count}")

        log_class_distribution(train_dataset, "EÄŸitim Seti")
        log_class_distribution(val_dataset, "DoÄŸrulama Seti")
        log_class_distribution(test_dataset, "Test Seti")
        exit(0)

    # Model, Optimizer, Scheduler
    model = BerturkClassifier(model_name=config["model_name"], num_labels=num_labels)
    model.bert.resize_token_embeddings(len(tokenizer))
    model.to(device)

    optimizer = AdamW(model.parameters(), lr=config["lr"])
    criterion = nn.CrossEntropyLoss()
    num_training_steps = len(train_loader) * config["epochs"]
    lr_scheduler = get_scheduler("linear",
                                    optimizer=optimizer,
                                    num_warmup_steps=0,
                                    num_training_steps=num_training_steps)

    start_epoch = 0
    best_val_acc = 0.0
    if os.path.exists(config["resume_checkpoint_path_multiclass"]):
        checkpoint = torch.load(config["resume_checkpoint_path_multiclass"], map_location=device)
        model.load_state_dict(checkpoint["model_state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        lr_scheduler.load_state_dict(checkpoint["scheduler_state_dict"])
        start_epoch = checkpoint["epoch"] + 1
        best_val_acc = checkpoint.get("best_val_acc", 0.0)  # Eski checkpoint'lerle uyumluluk iÃ§in .get()
        logging.info(f"Checkpoint bulundu, eÄŸitime {start_epoch}. epoch'tan devam ediliyor.")
    else:
        logging.info("Yeni bir eÄŸitim baÅŸlatÄ±lÄ±yor, checkpoint bulunamadÄ±.")

    for epoch in range(start_epoch, config["epochs"]):
        model.train()
        total_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{config['epochs']} (Multiclass)")
        for batch in progress_bar:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["label"].to(device)

            logits = model(input_ids, attention_mask)
            loss = criterion(logits, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            lr_scheduler.step()
            total_loss += loss.item()
            progress_bar.set_postfix(loss=f"{total_loss / (progress_bar.n + 1):.4f}")

        checkpoint_data = {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scheduler_state_dict": lr_scheduler.state_dict(),
            "best_val_acc": best_val_acc
        }
        torch.save(checkpoint_data, config["resume_checkpoint_path_multiclass"])

        # DeÄŸerlendirme
        val_acc, val_report = evaluate(model, val_loader, device, label_names_list)
        logging.info(f"\nEpoch {epoch + 1} - DoÄŸrulama BaÅŸarÄ±mÄ±: {val_acc:.4f}\n{val_report}")

        # En iyi modeli kaydetme
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            logging.info(f"ğŸš€ Yeni en iyi uzman model kaydediliyor: {best_val_acc:.4f}")
            torch.save(model.state_dict(), config["best_model_path_multiclass"])

    # EÄŸitim sonrasÄ± test
    logging.info("\n--- Uzman Model Test SÃ¼reci ---")
    model.load_state_dict(torch.load(config['best_model_path_multiclass']))
    test_acc, test_report = evaluate(model, test_loader, device, label_names_list)
    logging.info(f"\n--- UZMAN TEST SONUÃ‡LARI ---\nTest BaÅŸarÄ±mÄ±: {test_acc:.4f}\n{test_report}")


def main():
    output_dir = "checkpoints_v2/"
    config = {
        "batch_size": 16,
        "epochs": 30,  # Her adÄ±m iÃ§in epoch sayÄ±sÄ±
        "lr": 2e-5,
        "model_name": "dbmdz/bert-base-turkish-cased",
        "seed": 42,
        "print_labels": False,

        # AdÄ±m 1 iÃ§in yollar
        "checkpoint_path_binary": output_dir + "binary/",
        "best_model_path_binary": output_dir + "binary/best_model.pt",
        "label_encoder_binary_path": output_dir + "binary/label_encoder_binary.pkl",
        "resume_checkpoint_path_binary": output_dir + "binary/training_checkpoint.pt",

        # AdÄ±m 2 iÃ§in yollar
        "checkpoint_path_multiclass": output_dir + "multiclass/",
        "best_model_path_multiclass": output_dir + "multiclass/best_model.pt",
        "label_encoder_multiclass_path": output_dir + "multiclass/label_encoder_multiclass.pkl",
        "resume_checkpoint_path_multiclass": output_dir + "multiclass/training_checkpoint.pt"
    }

    # Her bir adÄ±ma Ã¶zel klasÃ¶rlerin oluÅŸturulduÄŸundan emin ol
    os.makedirs(config["checkpoint_path_binary"], exist_ok=True)
    os.makedirs(config["checkpoint_path_multiclass"], exist_ok=True)

    # Ä°ki adÄ±mÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±r
    train_top_level_classifier(config)
    train_expert_classifier(config)

    # TODO: EÄŸitim sonrasÄ± config kaydÄ±...
    logging.info("\nEÄŸitimler tamamlandÄ±. Ortak yapÄ±landÄ±rma dosyalarÄ± kaydediliyor...")

    # Tokenizer'Ä± (Ã¶zel token ile birlikte) yeniden oluÅŸturup kaydetmek,
    # her fonksiyonda ayrÄ± ayrÄ± tanÄ±mlandÄ±ÄŸÄ± iÃ§in en basit yoldur.
    tokenizer = AutoTokenizer.from_pretrained(config["model_name"])
    special_tokens_dict = {'additional_special_tokens': ['<CITE>']}
    tokenizer.add_special_tokens(special_tokens_dict)

    # KayÄ±t iÃ§in ortak bir ana klasÃ¶r belirleyelim (Ã¶rn: checkpoints_v2/)
    os.makedirs(output_dir, exist_ok=True)  # KlasÃ¶r yoksa oluÅŸtur

    tokenizer.save_pretrained(output_dir)
    logging.info(f"Tokenizer dosyalarÄ± (vocab.txt, added_tokens.json vb.) ÅŸuraya kaydedildi: {output_dir}")

    # EÄŸitim yapÄ±landÄ±rmasÄ±nÄ± JSON olarak kaydet
    config_path = os.path.join(output_dir, "training_config.json")
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=4, ensure_ascii=False)
    logging.info(f"YapÄ±landÄ±rma dosyasÄ± ÅŸuraya kaydedildi: {config_path}")


if __name__ == "__main__":
    main()